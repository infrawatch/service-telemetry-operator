- name: Clear the fact cache before looking up cluster information
  meta: clear_facts

- name: Get information about the cluster
  set_fact:
    api_groups: "{{ lookup('k8s', cluster_info='api_groups') }}"
  when:
  - not is_openshift
  - not is_k8s

- name: Show existing API groups available to us
  debug:
    var: api_groups

- name: Determine the cluster type
  set_fact:
    is_openshift: "{{ True if 'route.openshift.io' in api_groups else False }}"
    is_k8s: "{{ False if 'route.openshift.io' in api_groups else True }}"
  when:
  - not is_openshift
  - not is_k8s

- name: Indicate what kind of cluster we are in (OpenShift or Kubernetes).
  debug:
    msg: "CLUSTER TYPE: is_openshift={{ is_openshift }}; is_k8s={{ is_k8s }}"

- name: Fail when can't determine type of cluster
  fail:
    msg: "Cannot determine what type of cluster we are in"
  when:
  - not is_openshift
  - not is_k8s

- name: "Set supporting container image paths"
  set_fact:
    alertmanager_image_path: "{{ lookup('env', 'RELATED_IMAGE_ALERTMANAGER_IMAGE') | default('quay.io/prometheus/alertmanager:latest', true) }}" # noqa 204
    oauth_proxy_image: "{{ lookup('env', 'RELATED_IMAGE_OAUTH_PROXY_IMAGE') | default('quay.io/openshift/origin-oauth-proxy:latest', true) }}" # noqa 204
    prometheus_webhook_snmp_container_image_path: "{{ lookup('env', 'RELATED_IMAGE_PROMETHEUS_WEBHOOK_SNMP_IMAGE') | default('quay.io/infrawatch/prometheus-webhook-snmp:latest', true) }}" # noqa 204
    prometheus_image_path: "{{ lookup('env', 'RELATED_IMAGE_PROMETHEUS_IMAGE') | default('quay.io/prometheus/prometheus:latest', true) }}" # noqa 204

- name: Adjust defaults when highAvailability.enabled is true
  block:
  - name: Adjust alerting.alertmanager.deployment_size defaults for HA
    set_fact:
      servicetelemetry_vars: "{{ servicetelemetry_vars|combine({'alerting':{'alertmanager':{'deployment_size': 2}}}, recursive=True) }}" # noqa 206

  - name: Adjust backends.metrics.prometheus.deployment_size defaults for HA
    set_fact:
      servicetelemetry_vars: "{{ servicetelemetry_vars|combine({'backends':{'metrics':{'prometheus':{'deployment_size': 2}}}}, recursive=True) }}" # noqa 206

  - name: Adjust backends.events.elasticsearch.node_code defaults for HA
    set_fact:
      servicetelemetry_vars: "{{ servicetelemetry_vars|combine({'backends':{'events':{'elasticsearch':{'node_count': 3}}}}, recursive=True) }}" # noqa 206

  - name: Adjust transports.qdr.deployment_size defaults for HA
    set_fact:
      servicetelemetry_vars: "{{ servicetelemetry_vars|combine({'transports':{'qdr':{'deployment_size': 2}}}, recursive=True) }}" # noqa 206

  - name: Set collectd Smart Gateway deployment size
    set_fact:
      smartgateway_deployment_size: 2
  when: servicetelemetry_vars.high_availability.enabled

- name: Print some debug information
  vars:
    msg: |
      ServiceTelemetry Variables
      --------------------------------------------
      {{ servicetelemetry_vars | to_nice_yaml }}
  debug:
    msg: "{{ msg.split('\n') }}"

- name: Initialize Smart Gateway list
  set_fact:
    smartgateway_list: []

- name: Get current Smart Gateways loaded
  k8s_info:
    api_version: smartgateway.infra.watch/v2
    kind: SmartGateway
    namespace: "{{ ansible_operator_meta.namespace }}"
  register: smartgateways_loaded

- name: Get current STF object
  k8s_info:
    api_version: infra.watch/v1beta1
    kind: ServiceTelemetry
    name: "{{ ansible_operator_meta.name }}"
    namespace: "{{ ansible_operator_meta.namespace }}"
  register: _stf_object

- name: Get community Prometheus objects
  k8s_info:
    api_version: monitoring.coreos.com/v1
    kind: Prometheus
    name: "{{ ansible_operator_meta.name }}"
    namespace: "{{ ansible_operator_meta.namespace }}"
  register: _community_prom_object

- block:
  - name: Apply community observabilityStrategy if missing on an STF object with an existing community prometheus
    k8s:
      definition:
        apiVersion: infra.watch/v1beta1
        kind: ServiceTelemetry
        metadata:
          name: "{{ ansible_operator_meta.name }}"
          namespace: "{{ ansible_operator_meta.namespace }}"
        spec:
          observabilityStrategy: use_community
  - name: Set non-default community strategy for remainder of this run
    set_fact:
      observability_strategy: use_community
  when:
    - _community_prom_object.resources[0] is defined
    - _stf_object.resources[0].spec.observabilityStrategy is not defined

- name: Apply default observabilityStrategy if missing on a new STF object with no associated community prometheus
  k8s:
    definition:
      apiVersion: infra.watch/v1beta1
      kind: ServiceTelemetry
      metadata:
        name: "{{ ansible_operator_meta.name }}"
        namespace: "{{ ansible_operator_meta.namespace }}"
      spec:
        observabilityStrategy: "{{ observability_strategy }}"
  when:
    - _community_prom_object.resources[0] is not defined
    - _stf_object.resources[0].spec.observabilityStrategy is not defined

- name: Get QDR objects
  k8s_info:
    api_version: interconnectedcloud.github.io/v1alpha1
    kind: Interconnect
    name: "{{ ansible_operator_meta.name }}-interconnect"
    namespace: "{{ ansible_operator_meta.namespace }}"
  register: _qdr_object

- block:
  - name: Apply legacy auth=none for QDR if missing on the STF object and it's currently deployed that way
    k8s:
      definition:
        apiVersion: infra.watch/v1beta1
        kind: ServiceTelemetry
        metadata:
          name: "{{ ansible_operator_meta.name }}"
          namespace: "{{ ansible_operator_meta.namespace }}"
        spec:
          transports:
            qdr:
              auth: none

  - name: Set auth=none for remainder of this run
    set_fact:
      servicetelemetry_vars: "{{ servicetelemetry_vars|combine({'transports':{'qdr':{'auth': 'none'}}}, recursive=True) }}" # noqa 206
  when:
    - _stf_object.resources[0].spec.transports.qdr.auth is not defined
    - _qdr_object.resources[0] is defined and _qdr_object.resources[0].spec.edgeListeners[0].saslMechanisms == "ANONYMOUS"

- name: Apply default auth for QDR if missing on a new STF object with no associated auth=none QDR
  k8s:
    definition:
      apiVersion: infra.watch/v1beta1
      kind: ServiceTelemetry
      metadata:
        name: "{{ ansible_operator_meta.name }}"
        namespace: "{{ ansible_operator_meta.namespace }}"
      spec:
        transports:
          qdr:
            auth: "{{ servicetelemetry_defaults.transports.qdr.auth }}"
  when:
    - _stf_object.resources[0].spec.transports.qdr.auth is not defined
    - _qdr_object.resources[0] is defined and _qdr_object.resources[0].spec.edgeListeners[0].saslMechanisms != "ANONYMOUS"

- name: Set ephemeral_storage_enabled to true when storage strategy is ephemeral
  set_fact:
    _ephemeral_storage_enabled: true
  when:
    - servicetelemetry_vars.backends.metrics.prometheus.storage.strategy == "ephemeral" or
      servicetelemetry_vars.backends.events.elasticsearch.storage.strategy == "ephemeral" or
      servicetelemetry_vars.alerting.alertmanager.storage.strategy == "ephemeral"

- name: Set ServiceTelemetry object status to have ephemeralStorageEnabled status
  operator_sdk.util.k8s_status:
    api_version: infra.watch/v1beta1
    kind: ServiceTelemetry
    name: "{{ ansible_operator_meta.name }}"
    namespace: "{{ ansible_operator_meta.namespace }}"
    status:
      ephemeralStorageEnabled:
        status: "{{ _ephemeral_storage_enabled }}"
        lastTransitionTime: "{{ ansible_date_time.iso8601 }}"
        message: Ephemeral storage in use. Data loss when storage components are updated.
  when:
    (_stf_object.resources[0].status.ephemeralStorageEnabled is defined) and
    (_stf_object.resources[0].status.ephemeralStorageEnabled.status != _ephemeral_storage_enabled)
